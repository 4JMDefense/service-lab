version: '3.8'

services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    hostname: zookeeper
    networks:
      - my-network
    volumes:
      - /home/ubuntu/zookeeper/data:/opt/zookeeper-3.4.13/data
      - /home/ubuntu/logs:/logs

  kafka:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    ports:
      - "9092:9092"
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: "events:1:1"
      KAFKA_ADVERTISED_HOST_NAME: "ec2-44-229-192-171.us-west-2.compute.amazonaws.com"
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://ec2-44-229-192-171.us-west-2.compute.amazonaws.com:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/kafka-logs
      KAFKA_BROKER_ID: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/ubuntu/kafka:/kafka/kafka-logs
      - /home/ubuntu/logs:/logs
    depends_on:
      - zookeeper
    networks:
      - my-network
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/kafka/9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  db:
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: 'storage'
      MYSQL_USER: 'suser'
      MYSQL_PASSWORD: 'passpass'
      MYSQL_ROOT_PASSWORD: 'passpass'
    ports:
      - '3306:3306'
    expose:
      - '3306'
    volumes:
      - my-db:/var/lib/mysql
      - /home/ubuntu/logs:/logs
    networks:
      - my-network

  receiver:
    image: jmdizon5/receiver:latest
    ports:
      - "8080"
    depends_on:
      - kafka
    networks:
      - api.network
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/receiver:/config
      - /home/ubuntu/logs:/logs

  storage:
    image: jmdizon5/storage:latest
    ports:
      - "8090"
    depends_on:
      kafka:
        condition: service_healthy
      db:
        condition: service_started
    networks:
      - api.network
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/storage:/config
      - /home/ubuntu/logs:/logs

  processing:
    image: jmdizon5/processing:latest
    ports:
      - "8100"
    depends_on:
      - storage
    networks:
      - api.network
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/processing:/config
      - /home/ubuntu/logs:/logs
      - processing-db:/data  

  anomaly_detector:
    image: anomaly_detector:latest
    ports:
      - "8120"
    depends_on:
      - kafka
    networks:
      - api.network
    environment:
      - TARGET_ENV=test
      - KAFKA_HOST=kafka
      - KAFKA_PORT=9092
      - DATASTORE_PATH=/data/anomalies.json
      - THRESHOLD_BP=140
      - THRESHOLD_HR=40
    volumes:
      - /home/ubuntu/config/anomaly_detector:/config
      - /home/ubuntu/logs:/logs
      - anomaly-db:/data
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  analyzer:
    image: analyzer
    ports:
      - "8110"
    depends_on:
      - kafka
    networks:
      - api.network
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/analyzer:/config
      - /home/ubuntu/logs:/logs

  dashboard:
    image: dashboard
    ports:
      - "8888"
    networks:
      - api.network

  nginx:
    image: nginx:latest
    volumes:
      - /home/ubuntu/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - "receiver"
      - "storage"
      - "processing"
      - "analyzer"
      - "dashboard"
    networks:
      - api.network
    ports:
      - "80:80"

networks:
  my-network:
  api.network:

volumes:
  my-db:
  processing-db:
  anomaly-db:  # Declare volume for anomaly data storage

